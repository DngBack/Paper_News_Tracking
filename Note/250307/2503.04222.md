# Summary of 2503.04222.pdf

```markdown
# Summary of FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion

**Tổng quan**  
FuseChat-3.0 là một bộ các mô hình ngôn ngữ lớn (LLMs) được phát triển bằng cách tích hợp nhiều mô hình nguồn mạnh mẽ vào các mô hình mục tiêu nhỏ gọn hơn. Các mô hình nguồn bao gồm Gemma-2-27B-it, Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct và Llama-3.1-70B-Instruct, trong khi các mô hình mục tiêu tập trung vào các biến thể nhỏ hơn như Llama-3.1-8B-Instruct và các mô hình khác với số lượng tham số giảm xuống còn 1B.

**Đóng góp của bài viết**  
Bài viết này cung cấp cái nhìn sâu sắc về quy trình huấn luyện của FuseChat-3.0, bao gồm hai giai đoạn chính: tinh chỉnh có giám sát (SFT) để điều chỉnh phân phối mô hình và Tối ưu hóa Sở thích Trực tiếp (DPO) để tinh chỉnh mô hình mục tiêu dựa trên sở thích từ các mô hình nguồn.

**Tổng quan về kết quả**  
Kết quả cho thấy sự cải thiện đáng kể về hiệu suất trên nhiều nhiệm vụ, với mức tăng trung bình 6.8 điểm trên 14 tiêu chuẩn khi sử dụng Llama-3.1-8B-Instruct làm mô hình mục tiêu. Đặc biệt, mô hình này đạt được những cải tiến nổi bật trên các tiêu chuẩn theo dõi hướng dẫn, thiết lập hiệu suất tốt nhất mới cho các mô hình 8B tham số. Khung làm việc này kết hợp hiệu quả các điểm mạnh của các mô hình không đồng nhất, nâng cao độ bền và khả năng tổng quát trong khi giảm thiểu chi phí tính toán.

**Phương pháp thực hiện**  
Quá trình xây dựng dữ liệu là rất quan trọng, sử dụng một giao thức chuyên biệt để tạo ra các phản hồi từ các mô hình nguồn và tạo ra các cặp sở thích cho việc huấn luyện. Phương pháp này giúp giảm thiểu thiên lệch liên quan đến các đầu ra không đồng nhất, dẫn đến các tín hiệu sở thích được kiểm soát hơn. Việc đánh giá trên nhiều lĩnh vực, bao gồm theo dõi hướng dẫn, kiến thức chung, toán học và lập trình, cho thấy hiệu quả của FuseChat-3.0 trong việc nâng cao khả năng của các mô hình nhỏ hơn mà không cần tài nguyên tính toán lớn.

**Kết luận**  
Tổng thể, FuseChat-3.0 đại diện cho một bước tiến quan trọng trong các kỹ thuật hợp nhất mô hình, đạt được những cải thiện hiệu suất đáng kể trong khi vẫn duy trì hiệu quả.
```
