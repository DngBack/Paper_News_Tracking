# Summary of 2503.01901.pdf

# Challenges and Innovations in Serving Large Language Models

Bài báo này thảo luận về những thách thức trong việc phục vụ các Mô hình Ngôn ngữ Lớn (LLMs) do chi phí cao và yêu cầu bộ nhớ lớn. Nó nhấn mạnh tiềm năng của việc lượng tử hóa trọng số sau đào tạo để giảm kích thước mô hình và cải thiện hiệu suất. Tuy nhiên, các chỉ số nhạy cảm hiện có được sử dụng cho lượng tử hóa thường không chính xác, thường đánh giá thấp tác động của lượng tử hóa lên hàm mất mát.

Để giải quyết vấn đề này, các tác giả đề xuất một chỉ số mới gọi là **Post-quantization Integral (PQI)**, cung cấp một ước lượng chính xác hơn về độ nhạy bằng cách xem xét cả trọng số gốc và trọng số đã lượng tử hóa.

Ngoài ra, các tác giả cũng giới thiệu **ReQuant**, một khung lượng tử hóa sử dụng PQI để nâng cao hiệu suất mô hình thông qua phương pháp phân tích **Dense-and-Sparse**. Phương pháp này bao gồm việc chọn lọc tự thích ứng các điểm ngoại lai và tách biệt trọng số quan trọng theo từng bước để cải thiện kết quả lượng tử hóa. Kết quả thực nghiệm cho thấy ReQuant cải thiện đáng kể hiệu suất của các phương pháp lượng tử hóa hiện có, đạt được những cải tiến đáng kể về độ khó và độ chính xác trên nhiều LLM, bao gồm cả Llama 3.2.

Bài báo kết luận bằng cách thảo luận về những hạn chế của các phương pháp được đề xuất, chẳng hạn như nhu cầu lưu trữ ma trận thưa và những tác động tiềm tàng đến tốc độ suy diễn, đồng thời gợi ý các công việc trong tương lai để tích hợp PQI sâu hơn vào quy trình lượng tử hóa.
