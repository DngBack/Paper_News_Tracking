# Summary of 2503.02972.pdf

# LINGOLY-TOO: A Benchmark for Assessing Reasoning Capabilities of Large Language Models

Bài báo này giới thiệu LINGOLY-TOO, một bộ tiêu chuẩn được thiết kế để đánh giá khả năng suy luận của các Mô hình Ngôn ngữ Lớn (LLMs) trong khi giảm thiểu ảnh hưởng của việc ghi nhớ. Các tác giả đã phát triển một khung làm việc sử dụng phương pháp lập khuôn ngôn ngữ và làm mờ chính tả để tạo ra các bài toán suy luận ngôn ngữ đa dạng, được lấy cảm hứng từ Cuộc thi Ngôn ngữ học Vương quốc Anh, với hơn 90 ngôn ngữ ít tài nguyên. Cách tiếp cận này tạo ra nhiều biến thể câu hỏi mà vẫn giữ nguyên các bước suy luận cần thiết nhưng giảm khả năng các mô hình dựa vào câu trả lời đã ghi nhớ.

## Đóng góp của bài báo

Bài báo cung cấp một cái nhìn sâu sắc về khả năng suy luận của các LLM hiện đại, bao gồm Claude 3.7 Sonnet và GPT-4, cho thấy rằng chúng gặp khó khăn với các nhiệm vụ suy luận này. Kết quả cho thấy sự giảm hiệu suất đáng kể trên các bài toán đã được làm mờ so với các dạng gốc của chúng. Nghiên cứu nhấn mạnh sự không nhất quán trong hiệu suất của mô hình qua các biến thể bài toán khác nhau và gợi ý rằng việc tiếp xúc trước với dữ liệu huấn luyện có thể dẫn đến việc đánh giá quá cao khả năng suy luận của LLM.

## Tổng quan về kết quả và phương pháp

Bộ tiêu chuẩn bao gồm 27,325 câu hỏi, và các tác giả nhận thấy rằng việc làm mờ ảnh hưởng đến hiệu suất của mô hình tương tự nhau qua các phân ngành ngôn ngữ khác nhau. Đánh giá của con người cho thấy rằng việc làm mờ có thể làm tăng độ khó cảm nhận một chút, mặc dù các bước suy luận vẫn không thay đổi. Những phát hiện này nhấn mạnh sự cần thiết phải có các biện pháp mạnh mẽ để đánh giá khả năng suy luận trong các LLM, góp phần vào các cuộc thảo luận đang diễn ra về khả năng và giới hạn của chúng.
