# Summary of 2503.04369.pdf

# Lost in Literalism: How Supervised Training Shapes Translationese in LLMs

Bài báo "Lost in Literalism: How Supervised Training Shapes Translationese in LLMs" của Yafu Li và các cộng sự nghiên cứu vấn đề "translationese" - những bản dịch không tự nhiên và quá mức theo nghĩa đen - được tạo ra bởi các mô hình ngôn ngữ lớn (LLMs) trong dịch máy. Mặc dù LLMs đã đạt được nhiều thành công, nhưng chúng vẫn thể hiện nhiều lỗi translationese đáng kể, đặc biệt là do những thiên lệch được giới thiệu trong quá trình tinh chỉnh có giám sát (SFT). Các tác giả đã đánh giá một cách hệ thống sự phổ biến của translationese trong các đầu ra của LLM và xác định nguồn gốc của nó trong quá trình đào tạo.

## Đóng góp của bài báo

Bài báo cung cấp những phát hiện quan trọng, bao gồm:

1. Ngay cả những mô hình tiên tiến như GPT-4 cũng cho thấy hơn 40% bản dịch có các mẫu translationese đáng kể.
2. Nghiên cứu giới thiệu các phương pháp để giảm thiểu những thiên lệch này, chẳng hạn như tinh chỉnh các tài liệu tham khảo đào tạo và lọc các trường hợp đào tạo không tự nhiên, điều này đã cải thiện đáng kể tính tự nhiên của bản dịch.
3. Các đánh giá thực nghiệm xác nhận rằng những điều chỉnh này dẫn đến các bản dịch trôi chảy hơn, được xác thực bởi cả đánh giá của con người và các chỉ số tự động.

## Kết quả và phương pháp

Nghiên cứu nhấn mạnh tầm quan trọng của việc giải quyết chất lượng dữ liệu và phương pháp đào tạo để nâng cao đầu ra dịch thuật của LLM. Các tác giả đề xuất việc khám phá thêm các phương pháp này trên nhiều ngôn ngữ và lĩnh vực khác nhau nhằm tối ưu hóa các hệ thống dịch thuật.
