# Summary of 2503.01917.pdf

# Detecting Hallucinations in Large Language Models Using the Truthfulness Separator Vector

Bài báo này trình bày một phương pháp phát hiện hiện tượng ảo giác trong các mô hình ngôn ngữ lớn (LLMs) thông qua một cách tiếp cận mới gọi là Truthfulness Separator Vector (TSV). Hiện tượng ảo giác, hay các đầu ra không chính xác về mặt thực tế, là một mối quan tâm lớn đối với việc triển khai an toàn các LLM trong các ứng dụng thực tế. Các phương pháp truyền thống thường không thể phân biệt giữa nội dung chính xác và nội dung ảo giác do tập trung vào tính nhất quán ngôn ngữ thay vì độ chính xác thực tế.

## Đóng góp của bài báo

Phương pháp TSV được đề xuất là một vector điều khiển nhẹ, linh hoạt, có khả năng định hình lại không gian đại diện của LLM trong quá trình suy diễn, từ đó tăng cường sự phân tách giữa các đầu ra chính xác và ảo giác mà không cần thay đổi các tham số của mô hình. Phương pháp này sử dụng một khung đào tạo hai giai đoạn: giai đoạn đầu tiên sử dụng một tập hợp mẫu nhỏ có nhãn để tạo ra các cụm được phân tách tốt, trong khi giai đoạn thứ hai mở rộng tập hợp này bằng cách sử dụng các thế hệ LLM không có nhãn thông qua một thuật toán dựa trên vận chuyển tối ưu để gán nhãn giả.

## Kết quả và phương pháp

Các thí nghiệm rộng rãi cho thấy rằng TSV đạt được hiệu suất hàng đầu trong việc phát hiện hiện tượng ảo giác với lượng dữ liệu có nhãn tối thiểu, cho thấy khả năng tổng quát mạnh mẽ trên nhiều tập dữ liệu khác nhau. Phương pháp này vượt trội hơn so với các kỹ thuật hiện có, bao gồm cả các phương pháp hoàn toàn có giám sát, trong khi giảm đáng kể sự phụ thuộc vào việc gán nhãn của con người và chi phí tính toán. Những phát hiện này cho thấy rằng TSV cung cấp một giải pháp thực tiễn để cải thiện độ tin cậy của các LLM trong các ứng dụng quan trọng, mở đường cho các nghiên cứu trong tương lai về phát hiện hiện tượng ảo giác.
