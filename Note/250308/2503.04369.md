# Summary of 2503.04369.pdf

# Lost in Literalism: How Supervised Training Shapes Translationese in LLMs

Bài báo "Lost in Literalism: How Supervised Training Shapes Translationese in LLMs" của Yafu Li và các cộng sự nghiên cứu vấn đề translationese—các bản dịch không tự nhiên và quá mức theo nghĩa đen—do các mô hình ngôn ngữ lớn (LLMs) tạo ra trong dịch máy. Mặc dù LLMs đã đạt được nhiều thành công, nhưng chúng vẫn thể hiện nhiều lỗi translationese đáng kể do những thiên lệch được giới thiệu trong quá trình tinh chỉnh giám sát (SFT).

## Đóng góp của bài báo

Bài nghiên cứu này đánh giá một cách hệ thống sự phổ biến của translationese trong các đầu ra của LLM và xác định nguồn gốc của nó trong quy trình đào tạo giám sát. Các tác giả đã chỉ ra rằng ngay cả những mô hình tiên tiến như GPT-4 cũng tạo ra các bản dịch với hơn 40% có các mẫu translationese đáng kể.

## Phương pháp và kết quả

Các tác giả đề xuất các phương pháp để giảm thiểu những thiên lệch này, chẳng hạn như tinh chỉnh các tài liệu tham khảo đào tạo và lọc các trường hợp đào tạo không tự nhiên, điều này đã cải thiện đáng kể tính tự nhiên của bản dịch. Các đánh giá thực nghiệm xác nhận rằng những phương pháp này nâng cao độ lưu loát và tính nhất quán của các bản dịch.

## Kết luận

Những phát hiện này nhấn mạnh tầm quan trọng của việc giải quyết chất lượng dữ liệu và phương pháp đào tạo để tối ưu hóa đầu ra dịch thuật của LLM. Các tác giả cũng nhấn mạnh sự cần thiết phải nghiên cứu thêm để mở rộng các phương pháp này cho một loạt ngôn ngữ và lĩnh vực rộng hơn. Bài báo kết luận rằng mặc dù LLM có tiềm năng cho các bản dịch tự nhiên, nhưng hiệu suất của chúng có thể bị cản trở bởi các thiên lệch trong dữ liệu đào tạo.
