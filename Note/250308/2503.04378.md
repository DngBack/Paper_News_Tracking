# Summary of 2503.04378.pdf

# Enhancing Inference-Time Scaling with Feedback and Edit Models

Bài báo này thảo luận về sự phát triển của các Mô hình Phản hồi và Chỉnh sửa chuyên dụng nhằm nâng cao khả năng Mở rộng Thời gian Suy diễn cho các nhiệm vụ trong miền tổng quát không giới hạn. Các phương pháp truyền thống cho việc mở rộng thời gian suy diễn thường yêu cầu các câu trả lời có thể xác minh, điều này hạn chế tính khả thi của chúng. Được lấy cảm hứng từ quy trình học tập của con người, các tác giả đề xuất một hệ thống trong đó một mô hình tạo ra phản hồi ban đầu, một mô hình thứ hai cung cấp phản hồi, và một mô hình thứ ba chỉnh sửa phản hồi dựa trên phản hồi đó. Cách tiếp cận này đã cho thấy sự cải thiện hiệu suất đáng kể trên chuẩn Arena Hard, đạt được điểm số cao nhất 92.7, vượt qua các mô hình trước đó như o1-preview của OpenAI và DeepSeek R1.

Các tác giả đã thu thập dữ liệu từ hơn 7,000 người chú thích trên nhiều lĩnh vực khác nhau, đào tạo các mô hình để cung cấp phản hồi và chỉnh sửa hiệu quả. Họ nhấn mạnh tầm quan trọng của phản hồi phong phú và xây dựng để cải thiện các phản hồi của mô hình, đặc biệt là trong các nhiệm vụ phức tạp mà các phương pháp truyền thống có thể không đáp ứng được. Bài báo cũng chi tiết quy trình thu thập dữ liệu, đào tạo mô hình và các chỉ số đánh giá, chứng minh hiệu quả của cách tiếp cận của họ thông qua nhiều thí nghiệm và nghiên cứu loại bỏ.

Tóm lại, các Mô hình Phản hồi và Chỉnh sửa đại diện cho một bước tiến quan trọng trong lĩnh vực này, cho phép các phản hồi hiệu quả và có thể mở rộng hơn trong các nhiệm vụ mở, đồng thời cho phép tùy chỉnh và cá nhân hóa lớn hơn trong các hệ thống AI.
