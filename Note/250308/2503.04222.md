# Summary of 2503.04222.pdf

```markdown
# Summary of FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion

**Tổng quan:**  
FuseChat-3.0 là một bộ các mô hình ngôn ngữ lớn (LLMs) được phát triển bằng cách tích hợp nhiều mô hình nguồn mạnh mẽ vào các mô hình mục tiêu nhỏ gọn hơn. Các mô hình nguồn bao gồm Gemma-2-27B-it, Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct và Llama-3.1-70B-Instruct, trong khi các mô hình mục tiêu tập trung vào các biến thể nhỏ hơn như Llama-3.1-8B-Instruct và các mô hình khác với số lượng tham số giảm xuống còn 1B.

**Đóng góp của bài viết:**  
Bài viết này cung cấp cái nhìn sâu sắc về quy trình huấn luyện của FuseChat-3.0, bao gồm hai giai đoạn chính: tinh chỉnh có giám sát (SFT) để điều chỉnh phân phối mô hình và Tối ưu hóa Sở thích Trực tiếp (DPO) để tinh chỉnh mô hình mục tiêu dựa trên sở thích từ các mô hình nguồn.

**Tổng quan về kết quả:**  
Kết quả cho thấy sự cải thiện đáng kể về hiệu suất trên nhiều nhiệm vụ, với mức tăng trung bình 6.8 điểm trên 14 tiêu chuẩn khi sử dụng Llama-3.1-8B-Instruct làm mô hình mục tiêu. Đặc biệt, mô hình này đạt được những cải tiến nổi bật trên các tiêu chuẩn theo dõi hướng dẫn, thiết lập hiệu suất tốt nhất mới cho các mô hình 8B tham số.

**Phương pháp thực hiện:**  
Quy trình xây dựng dữ liệu là rất quan trọng, sử dụng một giao thức chuyên biệt để tạo ra các phản hồi từ các mô hình nguồn và tạo ra các cặp sở thích cho việc huấn luyện. Phương pháp này giúp giảm thiểu thiên lệch liên quan đến các phong cách phản hồi khác nhau, dẫn đến các tín hiệu sở thích được kiểm soát hơn.

**Kết luận:**  
Tổng thể, FuseChat-3.0 chứng minh tiềm năng của các mô hình nhỏ hơn có thể hoạt động tương đương với các mô hình lớn hơn, đạt được những cải tiến đáng kể về hiệu suất mà không cần tài nguyên tính toán lớn. Khung làm việc này đã được công khai, bao gồm mã nguồn, mô hình và tập dữ liệu.
```
