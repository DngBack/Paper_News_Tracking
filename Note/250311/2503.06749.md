# Summary of 2503.06749.pdf

# Vision-R1: Enhancing Reasoning in Multimodal Large Language Models

Bài báo này thảo luận về Vision-R1, một mô hình được thiết kế để nâng cao khả năng suy luận trong các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLMs) thông qua Học Tăng cường (RL). Tác giả nhấn mạnh những thách thức khi áp dụng trực tiếp RL cho MLLMs, đặc biệt là do thiếu dữ liệu suy luận đa phương thức chất lượng cao. Để giải quyết vấn đề này, họ đề xuất một phương pháp khởi tạo lạnh sử dụng một tập dữ liệu Chain-of-Thought (CoT) đa phương thức chất lượng cao được tạo ra mà không cần chú thích của con người, làm nền tảng cho việc đào tạo RL tiếp theo.

Mô hình Vision-R1 sử dụng chiến lược Đào tạo Giảm suy nghĩ Tiến bộ (PTST) để giảm thiểu Vấn đề Tối ưu hóa Suy nghĩ Quá mức, trong đó mô hình có xu hướng ưa chuộng các chuỗi suy luận ngắn hơn. Bằng cách tăng dần độ phức tạp của các nhiệm vụ suy luận, Vision-R1 có khả năng phát triển các quy trình suy luận tinh vi hơn. Mô hình này thể hiện hiệu suất mạnh mẽ trong các nhiệm vụ suy luận toán học, đạt được kết quả tương đương với các mô hình lớn hơn mặc dù có ít tham số hơn.

Bài báo bao gồm các thí nghiệm rộng rãi cho thấy Vision-R1 vượt trội hơn các mô hình hiện có trên nhiều tiêu chuẩn, đặc biệt là trong suy luận toán học. Tác giả cũng cung cấp một phân tích chi tiết về chất lượng tập dữ liệu và hiệu quả của các phương pháp được đề xuất, kết luận rằng Vision-R1 đại diện cho một bước tiến quan trọng trong việc khuyến khích khả năng suy luận trong MLLMs.
