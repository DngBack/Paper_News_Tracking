# Summary of 2503.07002.pdf

# Advancements in Multimodal Large Language Models (MLLMs)

Bài báo này thảo luận về những tiến bộ trong các mô hình ngôn ngữ lớn đa phương thức (MLLMs) và giới thiệu một tập dữ liệu mới, MMDiag, nhằm cải thiện việc học đối thoại đa phương thức nhiều lượt. Các MLLMs truyền thống thường gặp khó khăn với các tương tác phức tạp, nhiều lượt, chủ yếu được đào tạo trên các nhiệm vụ một lượt. MMDiag được thiết kế để phản ánh các cuộc trò chuyện trong thế giới thực, với sự tương quan mạnh mẽ giữa các câu hỏi và hình ảnh, nâng cao khả năng định hướng và lý luận của MLLMs.

Các tác giả đề xuất DiagNote, một MLLM bao gồm hai mô-đun: Deliberate và Gaze. Mô-đun Deliberate tập trung vào việc lý luận qua đối thoại, trong khi mô-đun Gaze giúp duy trì sự chú ý vào các chi tiết hình ảnh liên quan. Cách tiếp cận với hai mô-đun này cho phép DiagNote xử lý và lý luận hiệu quả với cả thông tin hình ảnh và văn bản qua nhiều lượt đối thoại.

Bài báo nêu bật những thách thức mà MMDiag đặt ra, cho thấy rằng các mô hình hiện có thường không duy trì được sự tập trung vào thông tin quan trọng, dẫn đến những sai sót. DiagNote cho thấy sự cải thiện đáng kể trong việc định hướng và lý luận, vượt trội hơn các mô hình khác trong nhiều kịch bản, bao gồm các nhiệm vụ hàng ngày, bảng và Minigrid.

Cuối cùng, các tác giả nhấn mạnh tầm quan trọng của việc định hướng và lý luận đa phương thức vững chắc trong việc phát triển MLLMs, với MMDiag đóng vai trò là một tiêu chuẩn cơ bản cho các nghiên cứu trong tương lai trong lĩnh vực này. Họ cũng thừa nhận những hạn chế trong cách tiếp cận của mình và đề xuất việc khám phá thêm các kiến trúc mô hình và các phương pháp đào tạo để nâng cao hiệu suất.
