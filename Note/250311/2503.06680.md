# Summary of 2503.06680.pdf

# FEA-Bench: Evaluating Large Language Models in Repository-Level Code Generation

## Overview
FEA-Bench là một bộ chuẩn mới được giới thiệu nhằm đánh giá khả năng của các mô hình ngôn ngữ lớn (LLMs) trong việc tạo mã ở cấp độ kho lưu trữ, đặc biệt là trong việc triển khai các tính năng mới. Các bộ chuẩn hiện tại chủ yếu tập trung vào các tác vụ lập trình độc lập, thiếu một khung để đánh giá sự phát triển gia tăng trong các mã nguồn.

## Contributions
FEA-Bench giải quyết khoảng trống này bằng cách sử dụng các pull request từ 83 kho lưu trữ trên GitHub, tạo ra 1,401 trường hợp tác vụ yêu cầu LLMs tạo ra các thành phần mới và chỉnh sửa mã liên quan. Mỗi tác vụ đều đi kèm với các bài kiểm tra đơn vị để xác minh tính chính xác của mã được tạo ra.

## Results Overview
Bộ chuẩn này làm nổi bật những thách thức mà LLMs phải đối mặt trong phát triển ở cấp độ kho lưu trữ, với các kết quả thử nghiệm cho thấy hiệu suất của chúng thấp hơn đáng kể so với các bộ chuẩn hiện có tập trung vào các tác vụ đơn giản hơn. 

## Methods
Quá trình xây dựng tập dữ liệu bao gồm việc lọc các pull request để đảm bảo rằng chúng tập trung vào việc phát triển tính năng mới, với một quy trình xác thực nghiêm ngặt nhằm duy trì chất lượng dữ liệu.

## Conclusion
FEA-Bench nhằm mục đích cung cấp một đánh giá toàn diện về khả năng tự động hóa kỹ thuật phần mềm của LLMs, nhấn mạnh sự cần thiết phải có những tiến bộ hơn nữa trong LLMs để giải quyết các thách thức kỹ thuật phần mềm trong thế giới thực. Bộ chuẩn và mã liên quan sẽ được công khai để phục vụ cho nghiên cứu và phát triển liên tục trong lĩnh vực này.
