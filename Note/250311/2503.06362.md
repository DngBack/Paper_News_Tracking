# Summary of 2503.06362.pdf

# Llama-MTSK: A Novel Matryoshka-based Multimodal Large Language Model for Audio-Visual Speech Recognition

Bài báo này giới thiệu Llama-MTSK, một mô hình ngôn ngữ lớn đa phương thức dựa trên Matryoshka, được thiết kế đặc biệt cho Nhận diện Giọng nói Âm thanh-Video (AVSR). Mô hình này tích hợp cả âm thanh và hình ảnh để cải thiện khả năng nhận diện giọng nói, đặc biệt trong các môi trường ồn ào. Các phương pháp truyền thống thường nén các đại diện giọng nói trước khi đưa vào các mô hình ngôn ngữ lớn, điều này có thể làm giảm hiệu suất. Llama-MTSK giải quyết vấn đề này bằng cách cho phép phân bổ token linh hoạt dựa trên các ràng buộc tính toán, đồng thời duy trì hiệu suất cao.

Mô hình sử dụng Học đại diện Matryoshka để mã hóa dữ liệu âm thanh-hình ảnh ở nhiều mức độ chi tiết khác nhau trong một khung duy nhất, loại bỏ nhu cầu về các mô hình riêng biệt cho các mức nén khác nhau. Nó giới thiệu ba chiến lược dựa trên LoRA cho việc tinh chỉnh hiệu quả, cho phép mô hình thích ứng với các nguồn tài nguyên tính toán và yêu cầu độ chính xác khác nhau.

Các đánh giá rộng rãi trên các tập dữ liệu LRS2 và LRS3 cho thấy Llama-MTSK đạt được kết quả tốt nhất trong lĩnh vực, vượt trội hơn so với các mô hình được đào tạo độc lập ở các mức nén cố định. Kiến trúc của mô hình cho phép điều chỉnh linh hoạt quá trình xử lý token trong quá trình suy diễn, nâng cao cả tính linh hoạt và hiệu quả tính toán. Tổng thể, Llama-MTSK thể hiện hiệu suất mạnh mẽ trong các nhiệm vụ AVSR trong khi giảm đáng kể chi phí tính toán so với các phương pháp truyền thống.
