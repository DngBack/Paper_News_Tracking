# Summary of 2502.17355.pdf

# Investigating Relation-Specific Neurons in Large Language Models

Bài nghiên cứu này khám phá sự tồn tại và chức năng của các nơ-ron đặc thù theo quan hệ trong các mô hình ngôn ngữ lớn (LLMs), đặc biệt là trong gia đình Llama-2. Các nơ-ron này được giả thuyết là tập trung vào các quan hệ cụ thể trong văn bản đầu vào, hướng dẫn việc tạo ra các đầu ra liên quan. Nghiên cứu sử dụng một phương pháp thống kê để xác định các nơ-ron này qua 12 loại quan hệ, tiết lộ ba đặc điểm chính:

1. **Tính Tích Lũy của Nơ-ron**: Việc vô hiệu hóa nhiều nơ-ron đặc thù theo quan hệ dẫn đến sự suy giảm lớn hơn của các sự thật liên quan đến quan hệ đó.
2. **Tính Đa Dạng của Nơ-ron**: Một số nơ-ron được chia sẻ giữa nhiều quan hệ và có khả năng chuyển giao kiến thức giữa các ngôn ngữ.
3. **Sự Can Thiệp của Nơ-ron**: Việc vô hiệu hóa nơ-ron cho một quan hệ có thể cải thiện hiệu suất cho các quan hệ khác, cho thấy sự tương tác phức tạp.

Các thí nghiệm cho thấy rằng các nơ-ron đặc thù theo quan hệ chủ yếu nằm ở các lớp giữa của mô hình và rất quan trọng cho việc xử lý kiến thức quan hệ. Những phát hiện này đóng góp vào việc hiểu cách mà các LLM mã hóa và hồi tưởng thông tin thực tế, làm nổi bật tính khả giải thích của các mô hình này. Nghiên cứu trong tương lai có thể khám phá một loạt các quan hệ và ngôn ngữ rộng hơn để xác thực thêm những phát hiện này.
