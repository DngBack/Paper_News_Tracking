# Summary of 2502.19587.pdf

```markdown
# NeoBERT: A Next-Generation BERT

**Tác giả:** Lola Le Breton, Quentin Fournier, Mariam El Mezouar, Sarath Chandar

## Tóm tắt
NeoBERT được giới thiệu như một mô hình mã hóa thế hệ tiếp theo, nâng cao khả năng của các mô hình hai chiều như BERT và RoBERTa bằng cách tích hợp các tiến bộ kiến trúc hiện đại, phương pháp tiền huấn luyện tối ưu và độ dài ngữ cảnh lớn hơn lên đến 4,096 token. Mặc dù có kích thước gọn nhẹ với 250 triệu tham số, NeoBERT đạt được kết quả hàng đầu trên chuẩn MTEB, vượt trội hơn các mô hình hiện có trong cùng điều kiện tinh chỉnh. Mô hình này được thiết kế để dễ dàng tích hợp vào các hệ thống hiện có và hoàn toàn mã nguồn mở, với tất cả tài nguyên liên quan được cung cấp cho nghiên cứu và ứng dụng thực tiễn.

## Giới thiệu
Những tiến bộ gần đây trong các mô hình ngôn ngữ tự hồi tiếp chưa được các mô hình mã hóa theo kịp, trong khi chúng vẫn rất quan trọng cho nhiều nhiệm vụ NLP. NeoBERT nhằm giải quyết khoảng cách này bằng cách tận dụng dữ liệu hiện đại và các kỹ thuật huấn luyện để nâng cao hiệu suất của mô hình mã hóa. Mô hình trải qua quá trình xác thực nghiêm ngặt thông qua việc tiền huấn luyện và tinh chỉnh rộng rãi, cho thấy sự cải thiện đáng kể so với các mô hình truyền thống.

## Các tính năng chính của NeoBERT
- **Kiến trúc:** Tích hợp tỷ lệ độ sâu và chiều rộng tối ưu, sử dụng Rotary Position Embeddings (RoPE) để cải thiện thông tin vị trí.
- **Sử dụng dữ liệu:** Được huấn luyện trên tập dữ liệu RefinedWeb rộng lớn, lớn hơn nhiều so với các tập dữ liệu trước đây được sử dụng cho tiền huấn luyện.
- **Tiền huấn luyện và tinh chỉnh:** Sử dụng quy trình huấn luyện hai giai đoạn để mở rộng độ dài ngữ cảnh và tối ưu hóa hiệu suất cho các nhiệm vụ hạ nguồn.
- **Hiệu suất:** Vượt trội hơn các mô hình hiện có trên các chuẩn như GLUE và MTEB, cho thấy khả năng hiệu quả và tổng quát vượt trội.

## Kết quả
NeoBERT liên tục đạt điểm cao hơn trên nhiều chuẩn so với các mô hình tiền nhiệm, chứng minh hiệu quả của nó trong việc xử lý các chuỗi dài và các nhiệm vụ phức tạp. Các lựa chọn thiết kế của mô hình, chẳng hạn như kích thước dữ liệu lớn hơn và các chiến lược huấn luyện tối ưu, góp phần vào hiệu suất nâng cao của nó.

## Kết luận
NeoBERT đại diện cho một bước tiến quan trọng trong các mô hình mã hóa, kết hợp các kỹ thuật tiên tiến với tính khả dụng thực tiễn. Tính chất mã nguồn mở của nó khuyến khích nghiên cứu và ứng dụng thêm trong lĩnh vực NLP, trong khi hiệu suất của nó thiết lập một tiêu chuẩn mới cho các phát triển trong kiến trúc mã hóa trong tương lai.
```
