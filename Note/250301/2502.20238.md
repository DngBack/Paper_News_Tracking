# Summary of 2502.20238.pdf

# Evaluating Reasoning Capabilities of Large Language Models with FINEREASON

Bài báo này giới thiệu FINEREASON, một bộ tiêu chuẩn được thiết kế để đánh giá khả năng suy luận của các mô hình ngôn ngữ lớn (LLMs) thông qua các câu đố logic. Nó nhấn mạnh tầm quan trọng của một quá trình suy luận có chủ đích và nhiều bước, đối lập với phản ứng nhanh "Hệ thống 1" và giải quyết vấn đề phản ánh "Hệ thống 2". Các bộ tiêu chuẩn hiện tại chủ yếu tập trung vào độ chính xác của câu trả lời cuối cùng, bỏ qua việc kiểm tra các bước suy luận trung gian, điều này rất quan trọng để đánh giá khả năng phản ánh và sửa chữa sai lầm của một mô hình.

## Đóng góp của bài báo

FINEREASON bao gồm bốn loại câu đố: Sudoku, Tô màu đồ thị, Trò chơi 24, và Câu đố lưới, mỗi loại cho phép đánh giá chi tiết khả năng suy luận thông qua hai nhiệm vụ: kiểm tra trạng thái (đánh giá xem một trạng thái có thể dẫn đến giải pháp hay không) và chuyển trạng thái (xác định bước đi hợp lệ tiếp theo). Bộ tiêu chuẩn này nhằm cung cấp một cái nhìn toàn diện hơn về quy trình suy luận của các LLM.

## Kết quả và phương pháp

Kết quả cho thấy các mô hình tập trung vào suy luận vượt trội hơn so với các mô hình đa năng trong cả hai nhiệm vụ, làm nổi bật những khoảng cách đáng kể trong khả năng suy luận sâu. Thêm vào đó, việc đào tạo trên dữ liệu câu đố của FINEREASON cải thiện hiệu suất trong các nhiệm vụ suy luận toán học, cho thấy rằng các kỹ năng phát triển thông qua việc giải quyết câu đố có thể nâng cao khả năng suy luận rộng hơn ở các LLM.

Bài nghiên cứu kết luận rằng FINEREASON cung cấp một công cụ quý giá để đánh giá và cải thiện khả năng suy luận của các LLM, nhấn mạnh sự cần thiết phải tập trung vào các quy trình suy luận trung gian thay vì chỉ dựa vào kết quả cuối cùng.
