# Summary of 2503.04872.pdf

# TinyR1-32B-Preview: Enhancing Accuracy in Large Language Models

Bài báo này giới thiệu mô hình TinyR1-32B-Preview, một giải pháp nhằm nâng cao độ chính xác trong các Mô Hình Ngôn Ngữ Lớn (LLMs) thông qua phương pháp chưng cất Branch-Merge mới. 

## Tóm tắt nội dung
Bài viết cung cấp cái nhìn sâu sắc về cách mà TinyR1-32B-Preview cải thiện hiệu suất của các mô hình ngôn ngữ lớn thông qua một quy trình chưng cất độc đáo. Phương pháp này bao gồm hai giai đoạn: 

1. **Giai đoạn Branch**: Trong giai đoạn này, kiến thức từ một mô hình giáo viên lớn được chưng cất vào các mô hình sinh viên chuyên biệt thông qua việc tinh chỉnh giám sát theo miền cụ thể.
2. **Giai đoạn Merge**: Giai đoạn này kết hợp các mô hình lại với nhau để tạo điều kiện cho việc chuyển giao kiến thức giữa các miền khác nhau.

## Đóng góp của bài báo
Mô hình TinyR1-32B-Preview đã vượt trội hơn so với người tiền nhiệm của nó, DeepSeek-R1-Distill-Qwen-32B, trong nhiều tiêu chuẩn đánh giá. Nó đạt được những cải tiến đáng kể trong các lĩnh vực Toán học, Lập trình và Khoa học, đồng thời duy trì hiệu suất tương đương với mô hình DeepSeek-R1 gốc. 

## Kết quả và phương pháp
Phương pháp này không chỉ cải thiện độ chính xác mà còn giảm chi phí tính toán và thời gian, tạo ra một giải pháp có thể mở rộng cho việc phát triển các mô hình LLM nhỏ hơn nhưng hiệu suất cao hơn. 

Các tác giả dự định phát hành mô hình và các tài nguyên liên quan để công chúng sử dụng. Công việc trong tương lai sẽ bao gồm việc khám phá các kiến trúc thay thế và mở rộng kích thước mô hình.
