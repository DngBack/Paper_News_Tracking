# Summary of 2503.05315.pdf

# LORACODE: LORA ADAPTERS FOR CODE EMBEDDINGS

Bài báo "LORACODE: LORA ADAPTERS FOR CODE EMBEDDINGS," được trình bày tại ICLR 2025, giới thiệu một phương pháp tinh chỉnh hiệu quả tham số mới sử dụng Low-Rank Adaptation (LoRA) nhằm nâng cao khả năng nhúng mã cho tìm kiếm mã ngữ nghĩa. Các mô hình hiện tại như CodeBERT và UniXcoder gặp khó khăn trong việc mở rộng và hiệu suất, trong khi các hệ thống độc quyền lại tốn kém chi phí.

## Đóng góp của bài báo

Phương pháp được đề xuất giảm số lượng tham số có thể huấn luyện xuống dưới 2% so với mô hình cơ sở, cho phép tinh chỉnh nhanh chóng trên các tập dữ liệu mã lớn (2 triệu mẫu trong 25 phút trên hai GPU H100). 

## Kết quả và phương pháp

Các thí nghiệm cho thấy sự cải thiện đáng kể trong Mean Reciprocal Rank (MRR) cho cả hai nhiệm vụ tìm kiếm Code2Code (tăng lên tới 9.1%) và Text2Code (tăng lên tới 86.69%) trên nhiều ngôn ngữ lập trình khác nhau. Nghiên cứu nhấn mạnh hiệu quả của các bộ điều chỉnh theo ngôn ngữ so với các bộ điều chỉnh theo nhiệm vụ, làm nổi bật tầm quan trọng của việc nắm bắt các sắc thái cú pháp và ngữ nghĩa trong việc truy xuất mã.

Bài báo kết thúc với kế hoạch tiếp tục khám phá các điều chỉnh theo ngôn ngữ trong tìm kiếm mã.
