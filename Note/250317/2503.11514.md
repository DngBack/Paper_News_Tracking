# Summary of 2503.11514.pdf

# Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks

Bài báo này nghiên cứu các rủi ro về quyền riêng tư liên quan đến Học Tập Liên Bang (Federated Learning - FL), đặc biệt là các cuộc tấn công Đảo Ngược Gradient (Gradient Inversion Attacks - GIA). Mặc dù FL được thiết kế để bảo vệ quyền riêng tư của dữ liệu bằng cách chỉ chia sẻ các gradient của mô hình, nhưng nghiên cứu đã chỉ ra rằng thông tin nhạy cảm vẫn có thể bị khai thác thông qua GIA. Các tác giả phân loại các phương pháp GIA thành ba loại: dựa trên tối ưu hóa (OP-GIA), dựa trên sinh (GEN-GIA) và dựa trên phân tích (ANA-GIA), đồng thời cung cấp một cái nhìn tổng quan và đánh giá hệ thống về các phương pháp này.

## Đóng góp của bài báo
Bài báo cung cấp cái nhìn sâu sắc về các phương pháp tấn công GIA và phân tích những điểm mạnh, điểm yếu của từng phương pháp. Điều này giúp các nhà nghiên cứu hiểu rõ hơn về các rủi ro tiềm ẩn trong FL và tìm ra các giải pháp để cải thiện tính bảo mật.

## Kết quả chính
1. **OP-GIA** là phương pháp thực tiễn nhất nhưng có hiệu quả hạn chế do phụ thuộc vào nhiều tham số huấn luyện khác nhau.
2. **GEN-GIA** thường yêu cầu các điều kiện cụ thể, chẳng hạn như phụ thuộc vào các bộ sinh đã được huấn luyện trước hoặc các hàm kích hoạt cụ thể, làm cho chúng ít thực tiễn hơn.
3. **ANA-GIA** có thể đạt được hiệu suất tấn công cao nhưng dễ bị phát hiện, giới hạn khả năng áp dụng của nó.

## Phương pháp đề xuất
Các tác giả đề xuất một quy trình phòng thủ ba giai đoạn nhằm nâng cao quyền riêng tư trong các hệ thống FL. Họ khuyến nghị tránh sử dụng một số hàm kích hoạt, sử dụng kích thước lô lớn hơn và thực hiện xác thực phía khách hàng để phát hiện các cuộc tấn công tiềm ẩn. Nghiên cứu này nhằm hướng dẫn các nhà nghiên cứu phát triển các khung FL mạnh mẽ hơn để giảm thiểu những điểm yếu này.
