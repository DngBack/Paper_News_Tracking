# Summary of 2503.11579.pdf

# VAMBA: A Hybrid Mamba-Transformer Model for Efficient Video Understanding

Bài báo này giới thiệu VAMBA, một mô hình hybrid Mamba-Transformer được thiết kế để hiểu video dài một giờ một cách hiệu quả. Các mô hình đa phương thức lớn dựa trên transformer truyền thống (LMMs) gặp khó khăn với các đầu vào video dài do độ phức tạp bậc hai trong tự chú ý nguyên nhân, dẫn đến chi phí tính toán cao. VAMBA giải quyết vấn đề này bằng cách sử dụng các khối Mamba-2 để mã hóa token video, đạt được độ phức tạp tuyến tính mà không cần giảm số lượng token. Điều này cho phép VAMBA xử lý hơn 1024 khung hình trên một GPU, giảm đáng kể mức sử dụng bộ nhớ GPU và tăng tốc độ đào tạo gần gấp đôi so với các mô hình hiện có.

Kiến trúc của VAMBA bao gồm các lớp chú ý chéo cho token văn bản và các khối Mamba cho token video, hiệu quả cân bằng giữa hiệu suất và sức mạnh biểu diễn. Kết quả thử nghiệm cho thấy VAMBA vượt trội hơn so với các mô hình LMMs video hiệu quả hàng đầu, đạt được cải thiện 4.3% độ chính xác trên benchmark LVBench và duy trì hiệu suất mạnh mẽ trên nhiều nhiệm vụ hiểu video khác nhau. Thiết kế của mô hình cho phép nó xử lý hiệu quả các đầu vào video dài, làm cho nó trở thành một giải pháp cạnh tranh trong lĩnh vực hiểu biết đa phương thức.
