# Summary of 2503.01449.pdf

# Benchmarking Large Language Models for Multi-Language Software Vulnerability Detection

Bài nghiên cứu này khám phá hiệu quả của các mô hình ngôn ngữ lớn (LLMs) trong việc phát hiện lỗ hổng phần mềm trên nhiều ngôn ngữ lập trình khác nhau, cụ thể là Python, Java và JavaScript. Nghiên cứu này giải quyết một khoảng trống quan trọng trong tài liệu hiện có, chủ yếu tập trung vào các tập dữ liệu C/C++ và các chiến lược đánh giá hạn chế.

## Đóng góp của bài nghiên cứu

Các tác giả đã biên soạn một tập dữ liệu gồm 8,260 hàm lỗ hổng trong Python, 7,505 trong Java và 28,983 trong JavaScript. Họ đã đánh giá năm mô hình LLM mã nguồn mở bằng nhiều phương pháp khác nhau, bao gồm kỹ thuật tạo prompt và tinh chỉnh mô hình. Các mô hình này được so sánh với các mô hình ngôn ngữ nhỏ hơn (SLMs) và các công cụ kiểm tra bảo mật ứng dụng tĩnh (SAST).

## Tóm tắt kết quả

Một số phát hiện chính bao gồm:
1. Các LLM thường gặp khó khăn trong việc phát hiện lỗ hổng phần mềm, với hiệu suất thay đổi đáng kể giữa các ngôn ngữ lập trình.
2. Kỹ thuật tạo prompt đã cải thiện hiệu suất của LLM trong Python và Java, trong khi tinh chỉnh mô hình lại hiệu quả hơn cho JavaScript.
3. SLMs vượt trội hơn LLMs trong Java và JavaScript nhưng lại kém hiệu quả hơn trong Python.
4. Nghiên cứu đã khám phá các phương pháp để nâng cao hiệu quả của LLM, chẳng hạn như đào tạo với các tập dữ liệu cân bằng và học tập tổ hợp, nhưng không đạt được thành công đáng kể.

Nghiên cứu nhấn mạnh tầm quan trọng của các đặc điểm tập dữ liệu và các chiến lược cụ thể cho từng mô hình trong việc phát hiện lỗ hổng, đồng thời gợi ý rằng công việc trong tương lai nên tập trung vào việc cải thiện khả năng của LLM và khám phá các kỹ thuật tiên tiến để nâng cao hiệu suất trong lĩnh vực bảo mật phần mềm.
