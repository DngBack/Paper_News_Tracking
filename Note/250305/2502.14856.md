# Summary of 2502.14856.pdf

# Enhancing Efficiency in Large-Vocabulary Language Models with FR-Spec

Bài báo này giới thiệu FR-Spec, một khung mẫu suy đoán được xếp hạng theo tần suất, nhằm nâng cao hiệu quả của các mô hình ngôn ngữ lớn (LLMs) trong quá trình sinh token. Các phương pháp mẫu suy đoán truyền thống, như EAGLE-2, sử dụng cơ chế "dự thảo rồi xác minh" nhưng gặp phải chi phí tính toán đáng kể khi xử lý các từ vựng lớn, chẳng hạn như 128k token trong Llama-3-8B. FR-Spec giải quyết vấn đề này bằng cách tối ưu hóa việc chọn lựa ứng viên dự thảo thông qua nén không gian từ vựng, tập trung vào một tập hợp token được ưu tiên theo tần suất. Cách tiếp cận này giảm thiểu 75% lượng tính toán cần thiết từ đầu ra của mô hình ngôn ngữ mà vẫn duy trì sự tương đương của phân phối đầu ra.

## Đóng góp của bài báo

Bài báo cung cấp cái nhìn sâu sắc về cách tối ưu hóa các hoạt động liên quan đến từ vựng để cải thiện hiệu quả của mẫu suy đoán trong các thiết lập từ vựng lớn. FR-Spec không chỉ tương thích với các kỹ thuật mẫu suy đoán hiện có mà còn không yêu cầu phải huấn luyện lại mô hình.

## Kết quả và phương pháp

Các thí nghiệm cho thấy FR-Spec đạt được tốc độ trung bình nhanh hơn 1.12 lần so với EAGLE-2 trên nhiều tập dữ liệu và nhiệm vụ khác nhau, bao gồm dịch máy, hội thoại và sinh mã. Những phát hiện này nhấn mạnh tầm quan trọng của việc tối ưu hóa các hoạt động liên quan đến từ vựng để cải thiện hiệu quả của mẫu suy đoán trong các thiết lập từ vựng lớn. Công việc trong tương lai có thể khám phá các cơ chế động để tăng tốc độ hơn nữa.
