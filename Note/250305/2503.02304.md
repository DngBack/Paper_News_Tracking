# Summary of 2503.02304.pdf

# TokenOCR: A Novel Token-Level Visual Foundation Model for Document Understanding

Bài báo này giới thiệu TokenOCR, một mô hình nền tảng thị giác cấp độ token mới, được thiết kế đặc biệt cho việc hiểu tài liệu, đặc biệt trong các nhiệm vụ liên quan đến tương tác giữa văn bản và hình ảnh. Nó giải quyết những hạn chế của các mô hình nền tảng thị giác hiện có (VFMs) thường dựa vào giám sát cấp độ hình ảnh, điều này thường dẫn đến sai sót trong các nhiệm vụ tinh vi như nhận diện văn bản nhỏ, dày đặc trong hình ảnh.

Để hỗ trợ sự phát triển của TokenOCR, các tác giả đã tạo ra TokenIT, bộ dữ liệu văn bản hình ảnh cấp độ token đầu tiên, bao gồm 20 triệu hình ảnh và 1.8 tỷ cặp token-mask. Bộ dữ liệu này cho phép mô hình học các biểu diễn ngữ nghĩa thị giác-văn bản mạnh mẽ bằng cách căn chỉnh các nhúng thị giác cấp độ token với các nhúng ngôn ngữ.

TokenOCR được tích hợp vào một mô hình ngôn ngữ lớn đa phương thức cấp độ tài liệu (MLLM) gọi là TokenVL, giúp cải thiện sự căn chỉnh giữa hình ảnh và ngôn ngữ cho các nhiệm vụ như trả lời câu hỏi hình ảnh (VQA). Các thí nghiệm rộng rãi cho thấy TokenOCR vượt trội hơn các mô hình hiện có như CLIP và SAM trong nhiều nhiệm vụ, chứng minh hiệu quả của nó trong các thiết lập không có sự huấn luyện trước và tính linh hoạt trong các ứng dụng khác nhau.

## Những đóng góp chính của công trình bao gồm:
1. Giới thiệu bộ dữ liệu TokenIT.
2. Phát triển mô hình TokenOCR cho các nhiệm vụ văn bản-hình ảnh đa dạng.
3. Tạo ra TokenVL để cải thiện việc hiểu tài liệu.
4. Xác thực các mô hình thông qua các thí nghiệm toàn diện, cho thấy sự cải thiện đáng kể trong các nhiệm vụ VQA và phân đoạn văn bản.

Các tác giả mong muốn các mô hình của họ sẽ trở thành các tiêu chuẩn có thể tái tạo cho các nghiên cứu trong tương lai về việc hiểu tài liệu đa phương thức.
