# Summary of 2503.02783.pdf

```markdown
# IterPref: Focal Preference Learning for Code Generation via Iterative Debugging

**Tác giả:** Jie Wu, Haoling Li, Xin Zhang, Jianwen Luo, Yangyu Huang, Ruihang Chu, Yujiu Yang, Scarlett Li

**Cơ quan:** Đại học Tsinghua, Nghiên cứu Microsoft, CASIA

## Tóm tắt
Bài viết này giới thiệu IterPref, một khung công tác mới nhằm nâng cao khả năng sinh mã trong các mô hình ngôn ngữ lớn (Code LLMs) thông qua việc học sở thích. Khác với phương pháp tinh chỉnh giám sát truyền thống, IterPref sử dụng các so sánh chất lượng tương đối. Các phương pháp hiện tại thường dựa vào tỷ lệ vượt qua từ các trường hợp kiểm tra để hình thành các cặp sở thích, nhưng thường bỏ qua những lỗi cụ thể trong mã. IterPref giải quyết vấn đề này bằng cách mô phỏng quy trình gỡ lỗi của con người, xác định các vùng lỗi và tinh chỉnh mã một cách lặp đi lặp lại. Nó giới thiệu tập dữ liệu CodeFlow, nơi các đoạn mã được cải thiện cho đến khi vượt qua các bài kiểm tra, cho phép trích xuất các cặp sở thích có thông tin. Các thí nghiệm cho thấy rằng các Code LLMs sử dụng IterPref đạt được sự cải thiện hiệu suất đáng kể trong các nhiệm vụ sinh mã, đặc biệt là trong các bài kiểm tra khó như BigCodeBench.

## Đóng góp chính
1. Giới thiệu IterPref, tận dụng gỡ lỗi lặp đi lặp lại để sửa lỗi tập trung trong Code LLMs.
2. Phát triển tập dữ liệu CodeFlow để tạo ra các cặp sở thích chất lượng cao thông qua tinh chỉnh lặp lại.
3. Đề xuất một thuật toán Tối ưu hóa Sở thích Trực tiếp (DPO) được điều chỉnh, nhấn mạnh các token quan trọng trong các mẫu không được ưa thích, nâng cao hiệu quả học tập.

## Kết quả
IterPref cho thấy sự cải thiện hiệu suất đáng kể trên nhiều bài kiểm tra, vượt trội hơn so với các phương pháp hiện có và thể hiện khả năng sửa lỗi tốt hơn. Khung công tác này hiệu quả trong việc giảm thiểu các lỗi lập trình phổ biến và cung cấp một con đường hiệu quả hơn cho việc chú thích sở thích so với các kỹ thuật lấy mẫu truyền thống.

## Hạn chế
Sự phụ thuộc của khung công tác vào các trường hợp kiểm tra được tạo ra có thể ảnh hưởng đến hiệu suất nếu chất lượng của các trường hợp này không được đảm bảo. Thêm vào đó, tập dữ liệu chỉ bao gồm 59k mẫu, điều này có thể hạn chế khả năng tổng quát nhưng cũng mở ra tiềm năng cho việc mở rộng trong tương lai.

## Kết luận
IterPref đại diện cho một bước tiến quan trọng trong việc học sở thích cho Code LLMs, cho phép phát hiện và sửa lỗi chính xác hơn thông qua một phương pháp gỡ lỗi lặp đi lặp lại có cấu trúc.
```
