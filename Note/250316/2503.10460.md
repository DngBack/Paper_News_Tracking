# Summary of 2503.10460.pdf

# Light-R1 Series: Training Long Chain-of-Thought Models from Scratch

Bài báo này thảo luận về chuỗi mô hình Light-R1, tập trung vào việc đào tạo các mô hình chuỗi suy nghĩ dài (COT) từ đầu bằng cách sử dụng phương pháp giảng dạy theo chương trình. Phương pháp này bao gồm hai giai đoạn tinh chỉnh có giám sát (SFT) và tối ưu hóa sở thích trực tiếp bán chính sách (DPO). Mô hình Light-R1-32B, được phát triển từ Qwen2.5-32B-Instruct, thể hiện hiệu suất toán học vượt trội và khả năng tổng quát trên nhiều lĩnh vực, đạt được kết quả tốt nhất trong nhiều tiêu chuẩn đánh giá (SOTA).

Một khía cạnh quan trọng của công trình này là việc tạo ra một tập dữ liệu chất lượng cao gồm 3k mẫu cho giai đoạn SFT thứ hai, điều này đã nâng cao hiệu suất của các mô hình khác, bao gồm Light-R1-7B-DS và Light-R1-14B-DS.

Các tác giả cũng đã áp dụng thành công học tăng cường (RL) cho mô hình Light-R1-14B-DS, đạt được những cải tiến đáng kể trong hiệu suất suy luận, vượt qua nhiều mô hình lớn hơn. Bài báo nhấn mạnh tầm quan trọng của một quy trình đào tạo được cấu trúc tốt, bao gồm thu thập dữ liệu, làm sạch và tạo dữ liệu, để đảm bảo việc đào tạo mô hình hiệu quả.

Kết quả cho thấy chuỗi mô hình Light-R1 có thể đào tạo hiệu quả các mô hình COT dài trong các môi trường hạn chế tài nguyên, cung cấp những hiểu biết quý giá về thiết kế chương trình giảng dạy và khả năng mở rộng của RL. Các mô hình, tập dữ liệu và mã nguồn đều được mở để phục vụ cho nghiên cứu tiếp theo trong lĩnh vực này.
