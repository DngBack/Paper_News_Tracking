# Summary of 2502.18890.pdf

# TOKENSWIFT: Accelerating Ultra-Long Sequence Generation with Large Language Models

Bài báo này giới thiệu TOKENSWIFT, một khung công tác được thiết kế để tăng tốc độ tạo ra các chuỗi siêu dài (lên đến 100K token) bằng cách sử dụng các mô hình ngôn ngữ lớn (LLMs). Các phương pháp truyền thống để tạo ra những chuỗi dài như vậy thường tốn thời gian, thường mất hàng giờ. TOKENSWIFT giải quyết ba thách thức chính: việc tải lại mô hình thường xuyên, quản lý khóa-giá trị (KV) động, và việc tạo ra nội dung lặp lại.

Bằng cách áp dụng các kỹ thuật như tạo nhiều token cùng lúc, tái sử dụng token, và cập nhật bộ nhớ KV động, TOKENSWIFT đạt được tốc độ tăng hơn 3 lần trên nhiều quy mô và kiến trúc mô hình khác nhau, giảm thời gian tạo ra từ khoảng 5 giờ xuống còn 90 phút cho 100K token. Khung công tác này duy trì chất lượng của văn bản được tạo ra trong khi nâng cao sự đa dạng và tính mạch lạc, biến nó thành một giải pháp có thể mở rộng cho các nhiệm vụ tạo ra chuỗi siêu dài.

Kết quả thử nghiệm cho thấy TOKENSWIFT liên tục vượt trội hơn so với các phương pháp hiện có, chẳng hạn như các mô hình tự hồi quy (AR) và các kỹ thuật giải mã suy đoán, trên nhiều mô hình và độ dài tiền tố khác nhau. Bài báo kết luận rằng TOKENSWIFT hiệu quả trong việc giảm thiểu các vấn đề liên quan đến nội dung lặp lại trong khi cải thiện đáng kể hiệu suất tạo ra.
