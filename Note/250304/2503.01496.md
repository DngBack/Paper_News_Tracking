# Summary of 2503.01496.pdf

# Liger: A Method for Linearizing Large Language Models

Bài báo này giới thiệu Liger, một phương pháp nhằm tuyến tính hóa các mô hình ngôn ngữ lớn (LLMs) thành các cấu trúc hồi tiếp có điều kiện, từ đó nâng cao hiệu quả trong quá trình huấn luyện và suy diễn. 

## Tóm tắt nội dung
Liger tái sử dụng trọng số từ các mô hình Transformer đã được huấn luyện trước để tạo ra các cơ chế gating mà không cần thêm tham số, cho phép triển khai hiệu quả. Phương pháp này sử dụng tinh chỉnh nhẹ thông qua Low-Rank Adaptation (LoRA) để phục hồi hiệu suất, đạt được kết quả cạnh tranh trên nhiều tiêu chuẩn với số lượng token huấn luyện trước tối thiểu.

## Đóng góp của bài báo
Cơ chế Liger Attention được đề xuất kết hợp giữa attention softmax cửa sổ trượt và mô hình hồi tiếp tuyến tính, cải thiện đáng kể khả năng phục hồi hiệu suất. Kết quả thực nghiệm cho thấy hiệu quả của Liger trên các mô hình có từ 1B đến 8B tham số, chứng minh tiềm năng của nó trong việc xử lý chuỗi dài một cách hiệu quả và giảm thiểu chi phí tính toán.

## Kết quả và phương pháp
Các phát hiện cho thấy Liger là một phương pháp hứa hẹn cho việc triển khai các LLM quy mô lớn, đồng thời giải quyết các thách thức về bộ nhớ và tốc độ.
