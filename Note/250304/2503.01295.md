# Summary of 2503.01295.pdf

```markdown
# CodeArena: A Collective Evaluation Platform for LLM Code Generation

**Tác giả:** Mingzhe Du, Anh Tuan Luu, Bin Ji, Xiaobao Wu, Dong Huang, Terry Yue Zhuo, Qian Liu, See-Kiong Ng

**Cơ quan:** Đại học Nanyang Technological, Đại học Quốc gia Singapore, Đại học Hồng Kông, Đại học Monash, ByteDance.

## Tóm tắt
CodeArena là một khung đánh giá trực tuyến được thiết kế để đánh giá khả năng sinh mã của các Mô hình Ngôn ngữ Lớn (LLMs). Nó giải quyết các thách thức như rò rỉ chuẩn mực, phân tán dữ liệu và khả năng tiếp cận hạn chế bằng cách triển khai cơ chế đánh giá tập thể, điều chỉnh điểm số của mô hình dựa trên hiệu suất tổng thể. Các tính năng chính bao gồm kho lưu trữ công khai các giải pháp và trường hợp kiểm tra, cùng với các API thân thiện với tự động hóa để đơn giản hóa quy trình đánh giá.

## Giới thiệu
Các LLM đã cách mạng hóa phát triển phần mềm bằng cách sinh mã từ các hướng dẫn bằng ngôn ngữ tự nhiên. Tuy nhiên, các phương pháp đánh giá hiện tại gặp phải vấn đề như ô nhiễm chuẩn mực, chia sẻ dữ liệu hạn chế và quy trình nộp phức tạp. CodeArena nhằm khắc phục những hạn chế này bằng cách cung cấp một hệ thống điểm động, một kho dữ liệu mở và các API thân thiện với người dùng.

## Đóng góp chính
1. **Đánh giá động:** CodeArena tích hợp các nhiệm vụ lập trình mới và điều chỉnh các chỉ số điểm để đánh giá hiệu quả các LLM.
2. **Kho dữ liệu mở:** Tất cả các giải pháp và trường hợp kiểm tra đều có sẵn công khai, thúc đẩy môi trường mã nguồn mở cho nghiên cứu LLM.
3. **API thân thiện với tự động hóa:** Các API hỗ trợ đánh giá mã tự động, nâng cao sự tương tác của người dùng.

## Tổng quan về khung
CodeArena bao gồm bốn lớp:
- **Lớp API:** Cung cấp các API RESTful cho các tương tác của người dùng.
- **Lớp Runtimes:** Cung cấp môi trường an toàn cho việc thực thi mã.
- **Lớp Đánh giá động:** Cập nhật điểm số dựa trên kết quả nộp.
- **Lớp Dữ liệu:** Lưu trữ các vấn đề, trường hợp kiểm tra và giải pháp.

## Quy trình làm việc
Người dùng có thể truy xuất các vấn đề, sinh mã, nộp giải pháp và theo dõi trạng thái nộp thông qua API. Nền tảng cũng hỗ trợ việc sinh trường hợp kiểm tra tự động để đảm bảo các đánh giá đa dạng và thách thức.

## Kết quả và thảo luận
CodeArena đã được khởi tạo với các chuẩn mực như APPS và Mercury, cho phép đánh giá toàn diện các LLM. Bảng xếp hạng của nền tảng phản ánh hiệu suất của các mô hình khác nhau, làm nổi bật sự khác biệt giữa các LLM mã nguồn mở và mã nguồn đóng.

## Kết luận
CodeArena đại diện cho một bước tiến quan trọng trong việc đánh giá khả năng sinh mã của LLM, thúc đẩy cải tiến do cộng đồng dẫn dắt và giải quyết các thách thức hiện có trong lĩnh vực này.

## Hạn chế
Nền tảng phụ thuộc vào các nguồn dữ liệu bên ngoài, điều này có thể ảnh hưởng đến chất lượng và tính khả dụng của các vấn đề. Cần có sự cải tiến liên tục để nâng cao chất lượng đánh giá.

## Tuyên bố đạo đức
CodeArena tuân thủ luật bản quyền và thúc đẩy sự công bằng trong các đánh giá bằng cách duy trì tính minh bạch và khả năng tiếp cận dữ liệu.

## Tài liệu tham khảo
Danh sách tài liệu tham khảo toàn diện được cung cấp, chi tiết các công trình và chuẩn mực cơ bản liên quan đến sự phát triển của CodeArena.
```
