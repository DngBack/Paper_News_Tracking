# Summary of 2502.19587.pdf

```markdown
# NeoBERT: A Next-Generation BERT

**Tác giả:** Lola Le Breton, Quentin Fournier, Mariam El Mezouar, Sarath Chandar

## Tóm tắt
Bài viết giới thiệu NeoBERT, một mô hình mã hóa thế hệ mới, nâng cao khả năng của các mô hình hai chiều như BERT và RoBERTa bằng cách tích hợp những tiến bộ gần đây trong kiến trúc, dữ liệu và phương pháp tiền huấn luyện. NeoBERT có kích thước 250 triệu tham số, độ dài ngữ cảnh mở rộng lên đến 4.096 token và đạt được kết quả tốt nhất trong các bài kiểm tra MTEB, vượt trội hơn so với các mô hình hiện có trong cùng điều kiện tinh chỉnh. Mô hình này được thiết kế để dễ dàng tích hợp vào các hệ thống hiện có và hoàn toàn mã nguồn mở, với tất cả tài nguyên liên quan được cung cấp cho nghiên cứu và ứng dụng thực tiễn.

## Giới thiệu
Trong khi các mô hình tự hồi quy như LLaMA đã có những bước tiến đáng kể, các mô hình mã hóa vẫn chưa theo kịp. NeoBERT nhằm mục đích khắc phục khoảng cách này bằng cách tận dụng dữ liệu hiện đại và các phương pháp huấn luyện tối ưu. Mô hình trải qua quy trình huấn luyện hai giai đoạn để nâng cao độ dài ngữ cảnh và hiệu suất trên nhiều nhiệm vụ NLP.

## Các tính năng chính của NeoBERT
- **Cải tiến kiến trúc:** Tích hợp tỷ lệ chiều sâu-chiều rộng tối ưu, Nhúng Vị trí Rotary (RoPE) và Chuẩn hóa Tầng Trung bình Căn bậc hai (RMSNorm) để cải thiện hiệu suất và hiệu quả.
- **Sử dụng dữ liệu:** Được huấn luyện trên tập dữ liệu RefinedWeb rộng lớn, lớn hơn nhiều so với các tập dữ liệu trước đây được sử dụng để huấn luyện các mô hình giống BERT.
- **Cải tiến tiền huấn luyện:** Tập trung hoàn toàn vào mô hình ngôn ngữ bị che khuất với tỷ lệ che khuất tăng lên, tối ưu hóa quy trình huấn luyện cho hiệu suất tốt hơn trong các nhiệm vụ hạ nguồn.

## Đánh giá hiệu suất
NeoBERT liên tục vượt trội hơn các mô hình hiện có trên các bài kiểm tra như GLUE và MTEB, cho thấy hiệu quả và hiệu suất vượt trội trong việc xử lý các chuỗi dài. Mô hình này đặc biệt nổi bật với khả năng xử lý các chuỗi lên đến 4.096 token, nâng cao đáng kể tính hữu dụng của nó trong các ứng dụng thực tế.

## Kết luận
NeoBERT đại diện cho một bước tiến quan trọng trong các mô hình mã hóa, kết hợp kiến trúc và kỹ thuật huấn luyện tiên tiến để đạt được hiệu suất cao trong khi vẫn dễ tiếp cận cho các nhà nghiên cứu và nhà phát triển. Tính chất mã nguồn mở của nó thúc đẩy sự minh bạch và hợp tác trong lĩnh vực NLP.
```
