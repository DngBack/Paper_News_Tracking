# Summary of 2502.16794.pdf

```markdown
# Mô Hình Ngôn Ngữ Lớn Dựa Trên Sự Chú Ý Âm Thanh (AAD-LLM)

Bài báo này trình bày về Mô Hình Ngôn Ngữ Lớn Dựa Trên Sự Chú Ý Âm Thanh (AAD-LLM), một mô hình tích hợp các tín hiệu thần kinh nhằm nâng cao khả năng hiểu biết về cảnh âm thanh bằng cách điều chỉnh phản ứng của máy với nhận thức âm thanh của con người. Các mô hình âm thanh truyền thống thường xử lý các tín hiệu âm thanh một cách đồng nhất, bỏ qua tính chất chọn lọc của sự chú ý con người trong những môi trường âm thanh phức tạp. AAD-LLM đã khắc phục hạn chế này bằng cách sử dụng điện não đồ nội sọ (iEEG) để giải mã người nghe đang tập trung vào người nói nào, từ đó tinh chỉnh phản ứng của mô hình dựa trên trạng thái chú ý này.

Mô hình hoạt động trong khuôn khổ Hiểu Biết Cảnh Âm Thanh Dựa Trên Ý Định (II-ASU), cho phép nó tạo ra các phản ứng phản ánh ý định của người nghe. AAD-LLM đã được đánh giá qua nhiều nhiệm vụ khác nhau, bao gồm mô tả người nói, phiên âm lời nói và trả lời câu hỏi, cho thấy hiệu suất cải thiện so với các mô hình hiện có. Kết quả cho thấy AAD-LLM hiệu quả trong việc điều chỉnh đầu ra của nó với nhận thức của người nghe, mở ra hướng đi cho các hệ thống AI âm thanh trực quan hơn.

Nghiên cứu này nhấn mạnh tiềm năng ứng dụng của AAD-LLM trong các công nghệ hỗ trợ nghe và trợ lý giọng nói thích ứng, đồng thời nhấn mạnh tầm quan trọng của việc tích hợp ý định của người nghe vào quá trình xử lý âm thanh. Các nghiên cứu trong tương lai sẽ khám phá các tín hiệu nhận thức rộng hơn và việc sử dụng các phương pháp ghi nhận thần kinh không xâm lấn để nâng cao khả năng áp dụng của mô hình trong các tình huống thực tế.
```
