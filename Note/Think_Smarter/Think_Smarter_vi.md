# ThinkSmarternotHarder: AdaptiveReasoningwith Inference AwareOptimization

Yu vÃ  cá»™ng sá»± (2025) giáº£i quyáº¿t thÃ¡ch thá»©c cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n khi sá»­ dá»¥ng chuá»—i suy luáº­n quÃ¡ dÃ i cho cÃ¡c bÃ i toÃ¡n toÃ¡n há»c Ä‘Æ¡n giáº£n. Há» giá»›i thiá»‡u Inference Budget-Constrained Policy Optimization (IBPO), má»™t thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a viá»‡c phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n dá»±a trÃªn Ä‘á»™ khÃ³ cá»§a truy váº¥n. IBPO tinh chá»‰nh mÃ´ hÃ¬nh Ä‘á»ƒ hiá»ƒu Ä‘á»™ phá»©c táº¡p cá»§a váº¥n Ä‘á» vÃ  phÃ¢n bá»• tÃ i nguyÃªn má»™t cÃ¡ch há»£p lÃ½, giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn cÃ¡c bÃ i toÃ¡n toÃ¡n há»c.

NghiÃªn cá»©u cho tháº¥y IBPO giÃºp mÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u quáº£ sá»­ dá»¥ng token tá»‘t hÆ¡n vÃ  tuÃ¢n thá»§ rÃ ng buá»™c, Ä‘á»“ng thá»i phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n má»™t cÃ¡ch linh hoáº¡t. CÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ phÃ¡t triá»ƒn IBPO tá»« gÃ³c Ä‘á»™ tá»‘i Æ°u hÃ³a, dáº«n Ä‘áº¿n má»™t báº£n cáº­p nháº­t SFT cÃ³ trá»ng sá»‘ Ä‘Æ¡n giáº£n dá»±a trÃªn cÃ¡c nguyÃªn táº¯c tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch cÃ³ rÃ ng buá»™c. Káº¿t quáº£ cho tháº¥y tiá»m nÄƒng cá»§a IBPO trong viá»‡c cÃ¢n báº±ng giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  chi phÃ­ tÃ­nh toÃ¡n trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM).

BÃ i bÃ¡o giáº£i quyáº¿t má»™t sá»‘ váº¥n Ä‘á» quan trá»ng liÃªn quan Ä‘áº¿n suy luáº­n trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs):

HÃ nh vi Ä‘Æ¡n cháº¿ Ä‘á»™ (uni-modal) trong cÃ¡c mÃ´ hÃ¬nh suy luáº­n chuá»—i dÃ i: CÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n cÃ³ xu hÆ°á»›ng sá»­ dá»¥ng chuá»—i suy luáº­n dÃ i má»™t cÃ¡ch khÃ´ng cáº§n thiáº¿t ngay cáº£ Ä‘á»‘i vá»›i cÃ¡c truy váº¥n Ä‘Æ¡n giáº£n, dáº«n Ä‘áº¿n chi phÃ­ suy luáº­n cao vÃ  gia tÄƒng dáº¥u chÃ¢n carbon.

Nhu cáº§u tá»‘i Æ°u hÃ³a Ä‘á»™ dÃ i suy luáº­n theo truy váº¥n: BÃ i bÃ¡o Ä‘á» xuáº¥t má»™t cÃ¡ch tiáº¿p cáº­n giÃºp mÃ´ hÃ¬nh suy luáº­n hoáº¡t Ä‘á»™ng theo hÃ nh vi Ä‘a cháº¿ Ä‘á»™ (multi-modal), trong Ä‘Ã³ Ä‘á»™ dÃ i chuá»—i suy luáº­n Ä‘Æ°á»£c tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh dá»±a trÃªn Ä‘á»™ phá»©c táº¡p cá»§a truy váº¥n.

CÃ¢n báº±ng giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  chi phÃ­ token: Má»¥c tiÃªu cá»§a nghiÃªn cá»©u lÃ  nÃ¢ng cao hiá»‡u suáº¥t sá»­ dá»¥ng token, Ä‘áº£m báº£o mÃ´ hÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t vá»›i má»©c tiÃªu thá»¥ token tá»‘i Æ°u.

Tá»‘i Æ°u hÃ³a phÃ¢n bá»• tÃ i nguyÃªn: BÃ i bÃ¡o Ä‘á» cáº­p Ä‘áº¿n bÃ i toÃ¡n kiá»ƒm soÃ¡t viá»‡c phÃ¢n bá»• pháº£n há»“i cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau, hÆ°á»›ng Ä‘áº¿n tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t suy luáº­n mÃ  khÃ´ng lÃ£ng phÃ­ tÃ i nguyÃªn tÃ­nh toÃ¡n.

ÄÃ¡p á»©ng rÃ ng buá»™c vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n: NghiÃªn cá»©u Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p giÃºp mÃ´ hÃ¬nh tuÃ¢n thá»§ cÃ¡c rÃ ng buá»™c ngÃ¢n sÃ¡ch suy luáº­n vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch Ä‘á»™ng nháº±m Æ°u tiÃªn tÃ i nguyÃªn cho cÃ¡c bÃ i toÃ¡n cÃ³ Ä‘á»™ phá»©c táº¡p cao hÆ¡n.

Thiáº¿t káº¿ thuáº­t toÃ¡n: XÃ¢y dá»±ng bÃ i toÃ¡n dÆ°á»›i dáº¡ng má»™t váº¥n Ä‘á» RL cÃ³ rÃ ng buá»™c vá»›i giá»›i háº¡n phÃ¢n bá»• tÃ i nguyÃªn, Ä‘á»“ng thá»i trÃ¬nh bÃ y cÃ¡ch dáº«n xuáº¥t thuáº­t toÃ¡n IBPO tá»« gÃ³c Ä‘á»™ tá»‘i Æ°u hÃ³a, dáº«n Ä‘áº¿n má»™t phÆ°Æ¡ng phÃ¡p cáº­p nháº­t SFT cÃ³ trá»ng sá»‘ theo tá»«ng bÆ°á»›c láº·p.

Triá»ƒn khai thá»±c táº¿: Cung cáº¥p chi tiáº¿t vá» cÃ¡ch triá»ƒn khai thuáº­t toÃ¡n IBPO, bao gá»“m viá»‡c lá»±a chá»n thuáº­t toÃ¡n cÆ¡ sá»Ÿ (Constraint Generative Policy Optimization - CGPO) vÃ  thiáº¿t káº¿ hÃ m thÆ°á»Ÿng. HÃ m thÆ°á»Ÿng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  reward margin, tá»©c lÃ  lá»£i tháº¿ pháº§n thÆ°á»Ÿng cá»§a nhÃ³m G so vá»›i táº¥t cáº£ cÃ¡c nhÃ³m khÃ¡c.

CÃ¡c thuáº­t ngá»¯, xÃ¢y dá»±ng G+ & quy trÃ¬nh huáº¥n luyá»‡n: Giáº£i thÃ­ch cÃ¡ch táº¡o pháº£n há»“i má»Ÿ rá»™ng, bao gá»“m Sequential Voting (SV) vÃ  Adaptive Sequential Voting (ASV). SV chá»‰ táº¡o pháº£n há»“i trong táº­p G+, trong khi ASV xuáº¥t ra há»—n há»£p cÃ¡c pháº£n há»“i thuá»™c
ğ‘¦
âˆˆ
ğº
âˆ˜
yâˆˆG
âˆ˜
vÃ 
ğ‘¦
âˆˆ
ğº

- yâˆˆG
- . Pháº§n nÃ y cÅ©ng trÃ¬nh bÃ y vá» táº­p dá»¯ liá»‡u vÃ  quy trÃ¬nh huáº¥n luyá»‡n sá»­ dá»¥ng trong thÃ­ nghiá»‡m.

ÄÃ¡nh giÃ¡ IBPO vá»›i OPTIuB: TrÃ¬nh bÃ y káº¿t quáº£ thá»±c nghiá»‡m cá»§a IBPO, thá»ƒ hiá»‡n kháº£ nÄƒng tuÃ¢n thá»§ rÃ ng buá»™c vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n má»™t cÃ¡ch linh hoáº¡t. CÃ¡c tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ bao gá»“m cáº£i thiá»‡n tuyá»‡t Ä‘á»‘i, hiá»‡u suáº¥t, tuÃ¢n thá»§ rÃ ng buá»™c vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch.

Káº¿t luáº­n & tháº£o luáº­n: Tá»•ng káº¿t láº¡i khung IBPO vÃ  nhá»¯ng lá»£i Ã­ch cá»§a nÃ³, bao gá»“m kháº£ nÄƒng tuÃ¢n thá»§ rÃ ng buá»™c vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n Ä‘á»™ng. Pháº§n nÃ y cÅ©ng tháº£o luáº­n vá» nhá»¯ng háº¡n cháº¿, á»©ng dá»¥ng rá»™ng hÆ¡n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn trong tÆ°Æ¡ng lai.

Phá»¥ lá»¥c:
VÃ­ dá»¥ pháº£n há»“i: Cung cáº¥p vÃ­ dá»¥ vá» pháº£n há»“i cá»§a ASV-IuB-50%, bao gá»“m cÃ¡c trÆ°á»ng há»£p cÃ³ sá»­ dá»¥ng voting vÃ  khÃ´ng sá»­ dá»¥ng voting.
TÃ­ch lÅ©y batch: ÄÆ°a ra cÃ¡ch triá»ƒn khai tÃ­ch lÅ©y batch cá»§a Thuáº­t toÃ¡n 1 Ä‘á»ƒ giáº£m bá»›t váº¥n Ä‘á» giá»›i háº¡n tÃ i nguyÃªn tÃ­nh toÃ¡n.
Giáº£i MILP: TrÃ¬nh bÃ y cÃ¡ch sá»­ dá»¥ng trÃ¬nh giáº£i MILP trong SciPy Ä‘á»ƒ tá»‘i Æ°u hÃ³a bÃ i toÃ¡n láº­p trÃ¬nh tuyáº¿n tÃ­nh nguyÃªn trong batch.
XÃ¢y dá»±ng dá»¯ liá»‡u: MÃ´ táº£ chi tiáº¿t cÃ¡c táº­p dá»¯ liá»‡u sá»­ dá»¥ng, bao gá»“m Qsdpo, Agolden sdpo, Qmath, vÃ  Asample math.
SiÃªu tham sá»‘: Liá»‡t kÃª cÃ¡c siÃªu tham sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c thÃ­ nghiá»‡m.
Tháº£o luáº­n thÃªm: Bao gá»“m cÃ¡c tháº£o luáº­n sÃ¢u hÆ¡n vá» rÃ ng buá»™c ngÃ¢n sÃ¡ch vÃ  CGPO trÃªn DRL vá»›i LLaMA.
BÃ i bÃ¡o káº¿t luáº­n ráº±ng khung IBPO giÃºp mÃ´ hÃ¬nh tuÃ¢n thá»§ rÃ ng buá»™c vÃ  phÃ¢n bá»• ngÃ¢n sÃ¡ch suy luáº­n má»™t cÃ¡ch linh hoáº¡t, tá»« Ä‘Ã³ cáº£i thiá»‡n hiá»‡u suáº¥t vÃ  hiá»‡u quáº£ trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n toÃ¡n há»c.
