# Summary of 2503.10589.pdf

# Long Context Tuning for Enhanced Video Generation

Bài báo này giới thiệu về **Long Context Tuning (LCT)**, một phương pháp huấn luyện mới nhằm nâng cao khả năng tạo video bằng cách đảm bảo tính nhất quán ở cấp độ cảnh trong các video nhiều cảnh. Các mô hình tạo video hiện tại rất giỏi trong việc tạo ra các video đơn cảnh thực tế, nhưng gặp khó khăn trong việc duy trì tính liên kết cần thiết cho các video kể chuyện bao gồm nhiều cảnh.

## Đóng góp của bài báo

LCT mở rộng cửa sổ ngữ cảnh của các mô hình khuếch tán video đơn cảnh đã được huấn luyện trước, cho phép chúng học được tính nhất quán ở cấp độ cảnh trực tiếp từ dữ liệu. Một số đổi mới chính bao gồm:

- **Cơ chế chú ý đầy đủ**: Được điều chỉnh để bao gồm tất cả các cảnh trong một video.
- **Embedding vị trí 3D xen kẽ**: Giúp cải thiện khả năng nhận diện vị trí trong video.
- **Chiến lược tiếng ồn không đồng bộ**: Cho phép tạo cảnh và cảnh tự động mà không cần thêm tham số.

## Kết quả và phương pháp

Các thí nghiệm cho thấy rằng các mô hình được huấn luyện với LCT có khả năng tạo ra các cảnh nhiều cảnh nhất quán, thể hiện khả năng như tạo hình thành phần và mở rộng cảnh tương tác. Phương pháp này vượt trội hơn so với các phương pháp hiện có về mặt tính nhất quán hình ảnh và ngữ nghĩa, mở ra cơ hội cho các ứng dụng thực tiễn hơn trong việc tạo nội dung video.

Bài báo cũng thảo luận về tiềm năng cho nghiên cứu trong tương lai về việc tạo video dài và việc tích hợp các mô hình ngôn ngữ lớn đa phương thức để nâng cao khả năng tạo video ở cấp độ cảnh.
