# Summary of 2503.10460.pdf

# Light-R1 Series: Training Long Chain-of-Thought Models from Scratch

Bài báo này thảo luận về chuỗi mô hình Light-R1, tập trung vào việc huấn luyện các mô hình chuỗi suy nghĩ dài (COT) từ đầu bằng cách sử dụng phương pháp giáo dục theo chương trình. Phương pháp này bao gồm hai giai đoạn: tinh chỉnh có giám sát (SFT) và tối ưu hóa sở thích trực tiếp bán chính sách (DPO). Mô hình Light-R1-32B, được phát triển từ Qwen2.5-32B-Instruct, cho thấy hiệu suất toán học vượt trội và khả năng tổng quát trên nhiều lĩnh vực, đạt được kết quả tốt nhất trong nhiều tiêu chuẩn đánh giá (SOTA).

Các tác giả nhấn mạnh tầm quan trọng của một tập dữ liệu được chọn lọc kỹ lưỡng với 3.000 mẫu để nâng cao hiệu suất của mô hình. Họ cũng báo cáo về việc huấn luyện thành công bằng học tăng cường (RL) trên mô hình Light-R1-14B-DS, mô hình này vượt trội hơn nhiều mô hình lớn hơn. Công trình này làm nổi bật tính khả thi của việc phát triển các mô hình suy luận nhỏ gọn nhưng mạnh mẽ, phù hợp cho các môi trường hạn chế tài nguyên.

Tất cả các mô hình, tập dữ liệu và mã nguồn đều được công khai để tạo điều kiện cho nghiên cứu tiếp theo. Những đóng góp chính của bài báo bao gồm:

- Một quy trình huấn luyện có thể tái tạo.
- Một tập dữ liệu chất lượng cao giúp cải thiện các mô hình hiện có.
- Ứng dụng thành công đầu tiên của học tăng cường trên các mô hình COT dài.
